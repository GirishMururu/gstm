/* =============================================================================
 *
 * thread.c
 *
 * =============================================================================
 *
 * Copyright (C) Stanford University, 2006.  All Rights Reserved.
 * Author: Chi Cao Minh
 *
 * =============================================================================
 *
 * For the license of bayes/sort.h and bayes/sort.c, please see the header
 * of the files.
 * 
 * ------------------------------------------------------------------------
 * 
 * For the license of kmeans, please see kmeans/LICENSE.kmeans
 * 
 * ------------------------------------------------------------------------
 * 
 * For the license of ssca2, please see ssca2/COPYRIGHT
 * 
 * ------------------------------------------------------------------------
 * 
 * For the license of lib/mt19937ar.c and lib/mt19937ar.h, please see the
 * header of the files.
 * 
 * ------------------------------------------------------------------------
 * 
 * For the license of lib/rbtree.h and lib/rbtree.c, please see
 * lib/LEGALNOTICE.rbtree and lib/LICENSE.rbtree
 * 
 * ------------------------------------------------------------------------
 * 
 * Unless otherwise noted, the following license applies to STAMP files:
 * 
 * Copyright (c) 2007, Stanford University
 * All rights reserved.
 * 
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are
 * met:
 * 
 *     * Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 * 
 *     * Redistributions in binary form must reproduce the above copyright
 *       notice, this list of conditions and the following disclaimer in
 *       the documentation and/or other materials provided with the
 *       distribution.
 * 
 *     * Neither the name of Stanford University nor the names of its
 *       contributors may be used to endorse or promote products derived
 *       from this software without specific prior written permission.
 * 
 * THIS SOFTWARE IS PROVIDED BY STANFORD UNIVERSITY ``AS IS'' AND ANY
 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL STANFORD UNIVERSITY BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 * THE POSSIBILITY OF SUCH DAMAGE.
 *
 * =============================================================================
 */

#ifndef _GNU_SOURCE
#define _GNU_SOURCE
#endif

#ifndef __USE_GNU
#define __USE_GNU
#endif
//Girish
//#define Profiling 

#include <assert.h>
#include <stdlib.h>
#include <stdio.h>
#include "thread.h"
#include "types.h"
#include <papi.h>
#include <time.h>
#include <unistd.h>
#include <stdint.h>
#include<sys/syscall.h>
#include <sched.h>
static THREAD_LOCAL_T    global_threadId;
static long              global_numThread       = 1;
static THREAD_BARRIER_T* global_barrierPtr      = NULL;
static long*             global_threadIds       = NULL;
static THREAD_ATTR_T     global_threadAttr;
static THREAD_T*         global_threads         = NULL;
static void            (*global_funcPtr)(void*) = NULL;
static void*             global_argPtr          = NULL;
static volatile bool_t   global_doShutdown      = FALSE;

#ifdef Profiling
int counter = 0;
int *acquisitionorder = NULL;
double *threadtime = NULL;
pthread_mutex_t aclock,reslock;
#endif
/* =============================================================================
 * threadWait
 * -- Synchronizes all threads to start/stop parallel section
 * =============================================================================
 */
#ifdef Profiling
double gettime()
{
	struct timespec tv;
	FILE *fp = NULL;
	if(clock_gettime(CLOCK_REALTIME,&tv) != 0){
		 fp = fopen("trialresults.txt","a+");
		 fprintf(fp,"Che timer error\n");
		 fclose(fp);
		 return 0;
	}
	return (((double) tv.tv_sec) +(double)(tv.tv_nsec/1.0e9));
}
long long **allocate_test_space(int num_tests, int num_events)
{
  long long **values;
  int i;

  values = (long long **)malloc(num_tests*sizeof(long long *));
  if (values==NULL)
    exit(1);
  memset(values,0x0,num_tests*sizeof(long long *));

  for (i=0;i<num_tests;i++)
    {
      values[i] = (long long *)malloc(num_events*sizeof(long long));
      if (values[i]==NULL)
        exit(1);
      memset(values[i],0x00,num_events*sizeof(long long));
    }
  return(values);
}
#endif

static void
threadWait (void* argPtr)
{
#ifdef Profiling
        #define SANDY 
        #ifdef SANDY
	#define NUM_EVENTS 15 
        int Events[NUM_EVENTS] = {PAPI_L1_DCM , PAPI_L1_ICM , PAPI_L2_ICM , PAPI_L2_TCM , PAPI_L3_TCM , PAPI_TLB_IM ,  PAPI_L2_STM , PAPI_STL_ICY , PAPI_BR_NTK , PAPI_BR_MSP , PAPI_L2_DCA ,  PAPI_L2_DCW,  PAPI_L3_DCW ,  PAPI_L3_TCA , PAPI_L3_TCW };
        /*#define NUM_EVENTS 30 
        int Events[NUM_EVENTS] = {PAPI_L1_DCM , PAPI_L1_ICM , PAPI_L2_ICM , PAPI_L2_TCM , PAPI_L3_TCM , PAPI_TLB_IM , PAPI_L1_STM , PAPI_L2_STM , PAPI_STL_ICY , PAPI_BR_NTK , PAPI_BR_MSP , PAPI_TOT_INS , PAPI_LD_INS , PAPI_SR_INS , PAPI_BR_INS , PAPI_TOT_CYC , PAPI_L2_DCA , PAPI_L2_DCR , PAPI_L3_DCR , PAPI_L2_DCW , PAPI_L3_DCW , PAPI_L2_ICH , PAPI_L2_ICA , PAPI_L3_ICA , PAPI_L2_ICR , PAPI_L3_ICR , PAPI_L3_TCA , PAPI_L3_TCW , PAPI_FDV_INS , PAPI_REF_CYC};*/
        #else
         #define NUM_EVENTS 47
        int Events[NUM_EVENTS]={PAPI_L1_DCM , PAPI_L1_ICM , PAPI_L2_ICM , PAPI_L2_TCM , PAPI_L3_TCM , PAPI_L3_LDM , PAPI_TLB_DM , PAPI_TLB_IM , PAPI_L1_LDM , PAPI_L1_STM , PAPI_L2_LDM , PAPI_L2_STM , PAPI_BR_UCN , PAPI_BR_CN , PAPI_BR_TKN , PAPI_BR_MSP , PAPI_TOT_IIS , PAPI_TOT_INS , PAPI_FP_INS , PAPI_LD_INS , PAPI_SR_INS , PAPI_BR_INS , PAPI_RES_STL , PAPI_TOT_CYC , PAPI_L1_DCA , PAPI_L2_DCA , PAPI_L1_DCR , PAPI_L2_DCR , PAPI_L3_DCR , PAPI_L1_DCW , PAPI_L2_DCW , PAPI_L3_DCW , PAPI_L1_ICH , PAPI_L2_ICH , PAPI_L1_ICA , PAPI_L2_ICA , PAPI_L3_ICA , PAPI_L1_ICR , PAPI_L2_ICR , PAPI_L3_ICR , PAPI_L2_TCA , PAPI_L3_TCA , PAPI_L2_TCW , PAPI_L3_TCW , PAPI_VEC_SP , PAPI_VEC_DP , PAPI_REF_CYC};
	#endif
	char EventStr[PAPI_MAX_STR_LEN];
        int EventSet = PAPI_NULL ;
        long long **values;
        int numvalues = 0;
        int addedEvents[NUM_EVENTS] = {'\0'};
	int e = 0;
#endif
    long threadId = *(long*)argPtr;
#ifdef Profiling	
    int myId ;//= thread_getId();
   double  Tstart = 0.0 ;
	double Tstop =0.0;
	int event = 0;	
	FILE *fp;
	long long start, stop , vstart, vstop;
        //cout<<"Number of  hardware counters is "<<PAPI_num_counters()<<endl;
        int retval ;
#endif
	//Pin the thread to the core
	cpu_set_t cpuset;
	pthread_t thread;
	thread = pthread_self();
	CPU_ZERO(&cpuset);
	CPU_SET(threadId,&cpuset);
	int st = pthread_setaffinity_np(thread,sizeof(cpu_set_t),&cpuset);
	if (st != 0)
	fprintf(stderr," Thread affinity not set for thread %ld",threadId);
	
    THREAD_LOCAL_SET(global_threadId, (long)threadId);

#ifdef Profiling
	retval = PAPI_create_eventset(&EventSet);
        if( retval != PAPI_OK){
                fprintf(stderr,"PAPI error create events %d: %s\n", retval, PAPI_strerror(retval));
                exit(1);
        }
        retval = PAPI_assign_eventset_component(EventSet,0);
        if( retval != PAPI_OK){
                fprintf(stderr,"PAPI error assign event set %d: %s\n", retval, PAPI_strerror(retval));
        }

        retval = PAPI_set_multiplex(EventSet);
        if( retval != PAPI_OK){
                fprintf(stderr,"PAPI error multiplex events %d: %s\n", retval, PAPI_strerror(retval));
        }
        for(e = 0; e < NUM_EVENTS; e++)
        {
                event = Events[e];
                retval = PAPI_add_event(EventSet,event);
                if( retval != PAPI_OK){
                        PAPI_event_code_to_name(event,EventStr);
                        fprintf(stderr,"PAPI error add event %s %d: %s\n",EventStr, retval, PAPI_strerror(retval));
                        continue;
                }
                addedEvents[numvalues++] = event;
        }
#endif
    while (1) {
        THREAD_BARRIER(global_barrierPtr, threadId); /* wait for start parallel */
        if (global_doShutdown) {
            break;
        }
#ifdef Profiling
        retval = PAPI_reset(EventSet);
        if( retval != PAPI_OK){
                fprintf(stderr,"PAPI error reset%d: %s\n", retval, PAPI_strerror(retval));
        }
        retval = PAPI_set_granularity(PAPI_GRN_THR);
        if( retval != PAPI_OK){
                fprintf(stderr,"PAPI error set granularity%d: %s\n", retval, PAPI_strerror(retval));
        }

	values = allocate_test_space(1, NUM_EVENTS);
	retval = PAPI_start(EventSet);
        if( retval != PAPI_OK){
                fprintf(stderr,"PAPI error start %d: %s\n", retval, PAPI_strerror(retval));
                exit(1);
        }
    	Tstart = gettime();
	start = PAPI_get_real_cyc();
	vstart = PAPI_get_virt_cyc();
#endif
        global_funcPtr(global_argPtr);
#ifdef Profiling	
	THREAD_MUTEX_LOCK(aclock);
	vstop = PAPI_get_virt_cyc();
	stop = PAPI_get_real_cyc();
	Tstop = gettime();
	retval = PAPI_stop(EventSet,values[0]);
        if( retval != PAPI_OK){
                fprintf(stderr,"PAPI error stop%d: %s\n", retval, PAPI_strerror(retval));
                exit(1);
        }
	myId = thread_getId();
	acquisitionorder[myId] = counter++;
	
	THREAD_MUTEX_UNLOCK(aclock);

	THREAD_MUTEX_LOCK(reslock);
	threadtime[myId] = (Tstop -  Tstart);
        fp = fopen("trialresults.txt","a+");
        fprintf(fp,"Thread:%d\n",myId);
        fprintf(fp,"time:%f\n",threadtime[myId]);
        fprintf(fp,"HammingDistance:%d\n",(acquisitionorder[myId] -myId));
	fprintf(fp,"RealCycles:%lld\n",(stop - start));
	fprintf(fp,"VirtCycles:%lld\n",(vstop - vstart));
        for( e = 0; e < numvalues; e++)
        {
                memset(EventStr,'\0',sizeof(EventStr));
                PAPI_event_code_to_name(addedEvents[e],EventStr);
                fprintf(fp,"%s:%lld\n",EventStr,values[0][e]);
        }
	fprintf(fp,"************************************************************************************************\n");
	fclose(fp);
        free(values[0]);
        free(values);
	THREAD_MUTEX_UNLOCK(reslock);
#endif
	
        THREAD_BARRIER(global_barrierPtr, threadId); /* wait for end parallel */
        if (threadId == 0) {
#ifdef Profiling
           counter = 0; 
#endif
	   break;
        }
    }

#ifdef Profiling
	retval = PAPI_cleanup_eventset(EventSet);
        if( retval != PAPI_OK){
                fprintf(stderr,"PAPI error cleanup%d: %s\n", retval, PAPI_strerror(retval));
        //      exit(1);
        }
        retval = PAPI_destroy_eventset(&EventSet);
        if( retval != PAPI_OK){
                fprintf(stderr,"PAPI error destroy%d: %s\n", retval, PAPI_strerror(retval));
        //      exit(1);
        }
#endif
	
}


/* =============================================================================
 * thread_startup
 * -- Create pool of secondary threads
 * -- numThread is total number of threads (primary + secondaries)
 * =============================================================================
 */
void
thread_startup (long numThread)
{
    long i;
	int retval = 0;
    global_numThread = numThread;
    global_doShutdown = FALSE;
#ifdef Profiling
	//Girish
	acquisitionorder = (int*) malloc(sizeof(int)*numThread);
	threadtime = (double*) malloc(sizeof(double)*numThread);
	THREAD_MUTEX_INIT(aclock);
	THREAD_MUTEX_INIT(reslock);
#endif
    /* Set up barrier */
    assert(global_barrierPtr == NULL);
    global_barrierPtr = THREAD_BARRIER_ALLOC(numThread);
    assert(global_barrierPtr);
    THREAD_BARRIER_INIT(global_barrierPtr, numThread);

    /* Set up ids */
    THREAD_LOCAL_INIT(global_threadId);
    assert(global_threadIds == NULL);
    global_threadIds = (long*)malloc(numThread * sizeof(long));
    assert(global_threadIds);
    for (i = 0; i < numThread; i++) {
        global_threadIds[i] = i;
    }

    /* Set up thread list */
    assert(global_threads == NULL);
    global_threads = (THREAD_T*)malloc(numThread * sizeof(THREAD_T));
    assert(global_threads);
	
#ifdef Profiling
	//Girish
	retval = PAPI_library_init(PAPI_VER_CURRENT);
        if( retval != PAPI_VER_CURRENT && retval > 0){
                fprintf(stderr,"PAPI error library init %d : %s\n",retval,PAPI_strerror(retval));
                exit(1);
        }
        retval = PAPI_multiplex_init();
        if(retval != PAPI_OK){
                fprintf(stderr,"PAPI error multiplex init %d : %s\n",retval,PAPI_strerror(retval));
                exit(1);
        }

        retval = PAPI_thread_init(pthread_self);
        if(retval != PAPI_OK){
                fprintf(stderr,"PAPI error thread init %d : %s\n",retval,PAPI_strerror(retval));
                exit(1);
        }
	//Mururu
#endif
    /* Set up pool */
    THREAD_ATTR_INIT(global_threadAttr);
    for (i = 1; i < numThread; i++) {
        THREAD_CREATE(global_threads[i],
                      global_threadAttr,
                      &threadWait,
                      &global_threadIds[i]);
    }

    /*
     * Wait for primary thread to call thread_start
     */
	
}


/* =============================================================================
 * thread_start
 * -- Make primary and secondary threads execute work
 * -- Should only be called by primary thread
 * -- funcPtr takes one arguments: argPtr
 * =============================================================================
 */
void
thread_start (void (*funcPtr)(void*), void* argPtr)
{
    global_funcPtr = funcPtr;
    global_argPtr = argPtr;

    long threadId = 0; /* primary */
    threadWait((void*)&threadId);
}


/* =============================================================================
 * thread_shutdown
 * -- Primary thread kills pool of secondary threads
 * =============================================================================
 */
void
thread_shutdown ()
{
    /* Make secondary threads exit wait() */
    global_doShutdown = TRUE;
    THREAD_BARRIER(global_barrierPtr, 0);

    long numThread = global_numThread;

    long i;
    for (i = 1; i < numThread; i++) {
        THREAD_JOIN(global_threads[i]);
    }

    THREAD_BARRIER_FREE(global_barrierPtr);
    global_barrierPtr = NULL;

    free(global_threadIds);
    global_threadIds = NULL;

    free(global_threads);
    global_threads = NULL;

    global_numThread = 1;
#ifdef Profiling
	//Girish
	free(acquisitionorder);
	free(threadtime);
	PAPI_shutdown();
	//Mururu
#endif
}


/* =============================================================================
 * thread_barrier_alloc
 * =============================================================================
 */
thread_barrier_t*
thread_barrier_alloc (long numThread)
{
    thread_barrier_t* barrierPtr;

    assert(numThread > 0);
    assert((numThread & (numThread - 1)) == 0); /* must be power of 2 */
    barrierPtr = (thread_barrier_t*)malloc(numThread * sizeof(thread_barrier_t));
    if (barrierPtr != NULL) {
        barrierPtr->numThread = numThread;
    }

    return barrierPtr;
}


/* =============================================================================
 * thread_barrier_free
 * =============================================================================
 */
void
thread_barrier_free (thread_barrier_t* barrierPtr)
{
    free(barrierPtr);
}


/* =============================================================================
 * thread_barrier_init
 * =============================================================================
 */
void
thread_barrier_init (thread_barrier_t* barrierPtr)
{
    long i;
    long numThread = barrierPtr->numThread;

    for (i = 0; i < numThread; i++) {
        barrierPtr[i].count = 0;
        THREAD_MUTEX_INIT(barrierPtr[i].countLock);
        THREAD_COND_INIT(barrierPtr[i].proceedCond);
        THREAD_COND_INIT(barrierPtr[i].proceedAllCond);
    }
}


/* =============================================================================
 * thread_barrier
 * -- Simple logarithmic barrier
 * =============================================================================
 */
void
thread_barrier (thread_barrier_t* barrierPtr, long threadId)
{
    long i = 2;
    long base = 0;
    long index;
    long numThread = barrierPtr->numThread;

    if (numThread < 2) {
        return;
    }

    do {
        index = base + threadId / i;
        if ((threadId % i) == 0) {
            THREAD_MUTEX_LOCK(barrierPtr[index].countLock);
            barrierPtr[index].count++;
            while (barrierPtr[index].count < 2) {
                THREAD_COND_WAIT(barrierPtr[index].proceedCond,
                                 barrierPtr[index].countLock);
            }
            THREAD_MUTEX_UNLOCK(barrierPtr[index].countLock);
        } else {
            THREAD_MUTEX_LOCK(barrierPtr[index].countLock);
            barrierPtr[index].count++;
            if (barrierPtr[index].count == 2) {
                THREAD_COND_SIGNAL(barrierPtr[index].proceedCond);
            }
            while (THREAD_COND_WAIT(barrierPtr[index].proceedAllCond,
                                    barrierPtr[index].countLock) != 0)
            {
                /* wait */
            }
            THREAD_MUTEX_UNLOCK(barrierPtr[index].countLock);
            break;
        }
        base = base + numThread / i;
        i *= 2;
    } while (i <= numThread);

    for (i /= 2; i > 1; i /= 2) {
        base = base - numThread / i;
        index = base + threadId / i;
        THREAD_MUTEX_LOCK(barrierPtr[index].countLock);
        barrierPtr[index].count = 0;
        THREAD_COND_SIGNAL(barrierPtr[index].proceedAllCond);
        THREAD_MUTEX_UNLOCK(barrierPtr[index].countLock);
    }
}


/* =============================================================================
 * thread_getId
 * -- Call after thread_start() to get thread ID inside parallel region
 * =============================================================================
 */
long
thread_getId()
{
    return (long)THREAD_LOCAL_GET(global_threadId);
}


/* =============================================================================
 * thread_getNumThread
 * -- Call after thread_start() to get number of threads inside parallel region
 * =============================================================================
 */
long
thread_getNumThread()
{
    return global_numThread;
}


/* =============================================================================
 * thread_barrier_wait
 * -- Call after thread_start() to synchronize threads inside parallel region
 * =============================================================================
 */
void
thread_barrier_wait()
{
#ifndef SIMULATOR
    long threadId = thread_getId();
#endif /* !SIMULATOR */
    THREAD_BARRIER(global_barrierPtr, threadId);
}


/* =============================================================================
 * TEST_THREAD
 * =============================================================================
 */
#ifdef TEST_THREAD


#include <stdio.h>
#include <unistd.h>


#define NUM_THREADS    (4)
#define NUM_ITERATIONS (3)



void
printId (void* argPtr)
{
    long threadId = thread_getId();
    long numThread = thread_getNumThread();
    long i;

    for ( i = 0; i < NUM_ITERATIONS; i++ ) {
        thread_barrier_wait();
        if (threadId == 0) {
            sleep(1);
        } else if (threadId == numThread-1) {
            usleep(100);
        }
        printf("i = %li, tid = %li\n", i, threadId);
        if (threadId == 0) {
            puts("");
        }
        fflush(stdout);
    }
}


int
main ()
{
    puts("Starting...");

    /* Run in parallel */
    thread_startup(NUM_THREADS);
    /* Start timing here */
    thread_start(printId, NULL);
    thread_start(printId, NULL);
    thread_start(printId, NULL);
    /* Stop timing here */
    thread_shutdown();

    puts("Done.");

    return 0;
}


#endif /* TEST_THREAD */


/* =============================================================================
 *
 * End of thread.c
 *
 * =============================================================================
 */
